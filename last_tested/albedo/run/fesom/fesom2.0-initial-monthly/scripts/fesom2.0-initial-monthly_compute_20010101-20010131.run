#!/usr/bin/bash
#SBATCH --partition=mpp
#SBATCH --time=00:08:00
#SBATCH --ntasks=288
#SBATCH --output=<TEST_DIR>/run/fesom//fesom2.0-initial-monthly/log/fesom2.0-initial-monthly_fesom_compute_20010101-20010131_%j.log --error=<TEST_DIR>/run/fesom//fesom2.0-initial-monthly/log/fesom2.0-initial-monthly_fesom_compute_20010101-20010131_%j.log
#SBATCH --job-name=fesom2.0-initial-monthly
#SBATCH --mail-type=NONE
#SBATCH --exclusive

module purge
module load intel-oneapi-compilers/2022.1.0
module load intel-oneapi-mkl/2022.1.0
module load openmpi/4.1.3
module load automake/1.16.1-oneapi2022.1.0
module load cdo/2.0.5
module load nco/5.0.1
module load git/2.35.2
module load udunits/2.2.28
module load netcdf-c/4.8.1-openmpi4.1.3-oneapi2022.1.0
module load netcdf-fortran/4.5.4-openmpi4.1.3-oneapi2022.1.0
module load hdf5/1.12.2-openmpi4.1.3-oneapi2022.1.0
module load python/3.10.4
module list

export LC_ALL=en_US.UTF-8
export FC=mpif90
export F77=mpif90
export MPIFC=mpif90
export MPICC=mpicc
export CC=mpicc
export CXX=mpicxx
export MPIROOT=$(mpif90 -show | perl -lne 'm{ -I(.*?)/include } and print $1')
export MPI_LIB=$(mpif90 -show |sed -e 's/^[^ ]*//' -e 's/-[I][^ ]*//g')
export HDF5ROOT=/albedo/soft/sw/spack-sw/hdf5/1.12.2-fknnmx5/
export HDF5_C_INCLUDE_DIRECTORIES=$HDF5ROOT/include
export HDF5_ROOT=$HDF5ROOT
export NETCDFFROOT=/albedo/soft/sw/spack-sw/netcdf-fortran/4.5.4-lzqfsg3/
export NETCDFROOT=/albedo/soft/sw/spack-sw/netcdf-c/4.8.1-sp3ulf4/
export NETCDF_Fortran_INCLUDE_DIRECTORIES=$NETCDFROOT/include
export NETCDF_CXX_INCLUDE_DIRECTORIES=$NETCDFROOT/include
export NETCDF_CXX_LIBRARIES=$NETCDFROOT/lib
export LAPACK_LIB="-lmkl_intel_lp64 -lmkl_core -mkl=sequential -lpthread -lm -ldl"
export LAPACK_LIB_DEFAULT="-L/global/AWIsoft/intel/2018/compilers_and_libraries_2018.5.274/linux/mkl/lib/intel64 -lmkl_intel_lp64 -lmkl_core -lmkl_sequential"
export ACCOUNT=None
export ESM_TESTING_DIR=<TEST_DIR>/run/fesom/
export MODEL_DIR=<TEST_DIR>/comp/fesom/fesom-2.0
export takenfrom=fesom2_run
export taken2from=fesom2_ru
export ENVIRONMENT_SET_BY_ESMTOOLS=TRUE

unset SLURM_MEM_PER_NODE
unset SLURM_MEM_PER_CPU

# Set stack size to unlimited
ulimit -s unlimited
# 3...2...1...Liftoff!

echo $(date +"%a %b  %e %T %Y") : compute 1 2001-01-01T00:00:00 2360158 - start >> <TEST_DIR>/run/fesom//fesom2.0-initial-monthly/log//fesom2.0-initial-monthly_fesom.log

cd <TEST_DIR>/run/fesom//fesom2.0-initial-monthly/run_20010101-20010131/work/
time srun -l --kill-on-bad-exit=1 --cpu_bind=cores --multi-prog hostfile_srun 2>&1 &

# Call to esm_runscript to start subjobs:
# ['tidy']
process=$! 
# Comment the following line if you don't want esm_runscripts to restart:
cd <TEST_DIR>/run/fesom//fesom2.0-initial-monthly/scripts/
esm_runscripts fesom2.0-initial-monthly.yaml -e fesom2.0-initial-monthly -t observe_compute -p ${process} -s 20010101 -r 1 -v  --last-jobtype prepcompute --open-run

echo $(date +"%a %b  %e %T %Y") : compute 1 2001-01-01T00:00:00 2360158 - done >> <TEST_DIR>/run/fesom//fesom2.0-initial-monthly/log//fesom2.0-initial-monthly_fesom.log

wait
