#!/usr/bin/bash
#SBATCH --partition=mpp
#SBATCH --time=00:30:00
#SBATCH --ntasks=864
#SBATCH --output=<TEST_DIR>/run/awiesm//pi/log/pi_awiesm_compute_18500101-18500101_%j.log --error=<TEST_DIR>/run/awiesm//pi/log/pi_awiesm_compute_18500101-18500101_%j.log
#SBATCH --job-name=pi
#SBATCH --account=clidyn.clidyn
#SBATCH --mail-type=NONE
#SBATCH --qos=30min
#SBATCH --exclusive

module purge
module load intel-oneapi-compilers/2022.1.0
module load intel-oneapi-mkl/2022.1.0-gcc12.1.0
module load openmpi/4.1.3-intel2021.6.0
module load udunits/2.2.28
module load hdf5/1.12.2-openmpi4.1.3-intel2021.6.0
module load netcdf-c/4.8.1-openmpi4.1.3-intel2021.6.0
module load netcdf-fortran/4.5.4-openmpi4.1.3-intel2021.6.0
module load netcdf-cxx4/4.3.1-openmpi4.1.3-intel2021.6.0
module load eccodes/2.25.0-openmpi4.1.3-intel2021.6.0
module load cdo/2.0.5
module load nco/5.0.1
module load git/2.35.2
module load python/3.10.4
module list

export LC_ALL=en_US.UTF-8
export FC=mpif90
export F77=mpif90
export MPIFC=mpif90
export MPICC=mpicc
export CC=mpicc
export CXX=mpic++
export CPU_MODEL=AMD_EPYC_ZEN2
export FESOM_PLATFORM_STRATEGY=albedo
export PERL5LIB=<HOME_DIR>/my_libs/perl-5.32.0/lib
export HDF5ROOT=/albedo/soft/sw/spack-sw/hdf5/1.12.2-mstdrjw/
export NETCDFROOT=/albedo/soft/sw/spack-sw/netcdf-c/4.8.1-vvxxdc3/
export NETCDFFROOT=/albedo/soft/sw/spack-sw/netcdf-fortran/4.5.4-uwfs3bu/
export ECCODESROOT=/albedo/soft/sw/spack-sw/eccodes/2.25.0-vn2k575/
export OASIS3MCT_FC_LIB="-L$NETCDFFROOT/lib -lnetcdff"
export MPIROOT=$(mpif90 -show | perl -lne 'm{ -I(.*?)/include } and print $1')
export MPI_LIB=$(mpif90 -show |sed -e 's/^[^ ]*//' -e 's/-[I][^ ]*//g')
export LAPACK_LIB='-L/albedo/soft/sw/spack-sw/intel-oneapi-mkl/2022.1.0-akthm3n/mkl/2022.1.0 -lmkl_intel_lp64 -lmkl_core -lmkl_sequential -lm -ldl'
export LD_LIBRARY_PATH=/albedo/soft/sw/spack-sw/intel-oneapi-mkl/2022.1.0-akthm3n/mkl/2022.1.0/lib/intel64:$LD_LIBRARY_PATH
export PATH=$PERL5LIB/../bin:$PATH
export PATH=$PATH:$ECCODESROOT/bin
export ACCOUNT=clidyn.clidyn
export ESM_TESTING_DIR=<TEST_DIR>/run/awiesm/
export MODEL_DIR=<TEST_DIR>/comp/awiesm/awiesm-2.1
export ENVIRONMENT_SET_BY_ESMTOOLS=TRUE

unset SLURM_MEM_PER_NODE
unset SLURM_MEM_PER_CPU

# Set stack size to unlimited
ulimit -s unlimited
# 3...2...1...Liftoff!

echo $(date +"%a %b  %e %T %Y") : compute 1 1850-01-01T00:00:00 761724 - start >> <TEST_DIR>/run/awiesm//pi/log//pi_awiesm.log

cd <TEST_DIR>/run/awiesm//pi/run_18500101-18500101/work/
time srun -l --kill-on-bad-exit=1 --cpu_bind=cores --multi-prog hostfile_srun 2>&1 &

# Call to esm_runscript to start subjobs:
# ['tidy']
process=$! 
# Comment the following line if you don't want esm_runscripts to restart:
cd <TEST_DIR>/run/awiesm//pi/scripts/
esm_runscripts pi.yaml -e pi -t observe_compute -p ${process} -s 18500101 -r 1 -v  --last-jobtype prepcompute --open-run

echo $(date +"%a %b  %e %T %Y") : compute 1 1850-01-01T00:00:00 761724 - done >> <TEST_DIR>/run/awiesm//pi/log//pi_awiesm.log

wait
